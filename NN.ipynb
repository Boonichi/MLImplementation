{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.4\n",
      "0.4\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.7133333333333334\n",
      "0.7133333333333334\n",
      "0.6733333333333333\n",
      "0.6733333333333333\n",
      "0.6933333333333334\n",
      "0.6933333333333334\n",
      "0.6933333333333334\n",
      "0.8066666666666666\n",
      "0.8066666666666666\n",
      "0.8066666666666666\n",
      "0.7\n",
      "0.8733333333333333\n",
      "0.8733333333333333\n",
      "0.8733333333333333\n",
      "0.7\n",
      "0.7\n",
      "0.8066666666666666\n",
      "0.7733333333333333\n",
      "0.7733333333333333\n",
      "0.9133333333333333\n",
      "0.9133333333333333\n",
      "0.9133333333333333\n",
      "0.8266666666666667\n",
      "0.9266666666666666\n",
      "0.9266666666666666\n",
      "0.7733333333333333\n",
      "0.7733333333333333\n",
      "0.7733333333333333\n",
      "0.92\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.86\n",
      "0.86\n",
      "0.9666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.96\n",
      "0.96\n",
      "0.8933333333333333\n",
      "0.8933333333333333\n",
      "0.9666666666666667\n",
      "0.8733333333333333\n",
      "0.8733333333333333\n",
      "0.8733333333333333\n",
      "0.96\n",
      "0.96\n",
      "0.8866666666666667\n",
      "0.8866666666666667\n",
      "0.96\n",
      "0.96\n",
      "0.8866666666666667\n",
      "0.8866666666666667\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n",
      "0.9533333333333334\n",
      "0.9666666666666667\n",
      "0.9\n",
      "0.9\n",
      "0.9\n",
      "0.9666666666666667\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import math\n",
    "import random as rd\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "def o(W,x):\n",
    "  sum = W[0]\n",
    "  for i in range(len(W)-1):\n",
    "    sum += W[i+1]*x[i]\n",
    "  return math.exp(sum)/(1+math.exp(sum))\n",
    "\n",
    "def layout(WW,x):\n",
    "  return [o(W,x) for W in WW]\n",
    "\n",
    "def network(WWW,x):\n",
    "  for WW in WWW:\n",
    "    x = layout(WW,x)\n",
    "  return x\n",
    "\n",
    "def e(WWW,X,Y):\n",
    "  sum = 0\n",
    "  for i in range(len(X)):\n",
    "    net_o = network(WWW,X[i])\n",
    "    O = [0]*len(net_o)\n",
    "    O[Y[i]] = 1\n",
    "    for j in range(len(net_o)):\n",
    "      sum += (O[j]-net_o[j])**2\n",
    "  return sum\n",
    "\n",
    "def e1(WWW,k,j,i,X,Y):\n",
    "  d = 0.0000001\n",
    "  WWW_ = [[W[:] for W in WW] for WW in WWW]\n",
    "  WWW_[k][j][i] += d\n",
    "  return (e(WWW_,X,Y) - e(WWW,X,Y))/d\n",
    "\n",
    "def acc(model):\n",
    "  count = 0\n",
    "  for i in range(len(X)):\n",
    "    maxj = 0\n",
    "    maxV = 0\n",
    "    oo = network(model,X[i])\n",
    "    for j in range(len(oo)):\n",
    "      if maxV<oo[j]:\n",
    "        maxV=oo[j]\n",
    "        maxj=j\n",
    "    if Y[i] == maxj:\n",
    "      count +=1\n",
    "  print(count/len(X))\n",
    "\n",
    "def learnModel(X,Y,struct,droprate):\n",
    "  WWW = [[[0]*(struct[i]+1)]*struct[i+1] for i in range(len(struct)-1)]\n",
    "  alpha = 1\n",
    "  for _ in range(100):\n",
    "    W_new = [[W[:] for W in WW] for WW in WWW]\n",
    "    for k in range(len(WWW)):\n",
    "      for j in range(len(WWW[k])):\n",
    "        for i in range(len(WWW[k][j])):\n",
    "          if (rd.random()>droprate):\n",
    "            W_new[k][j][i] = WWW[k][j][i] - alpha*e1(WWW,k,j,i,X,Y)\n",
    "    e_new = e(W_new,X,Y)\n",
    "    e_ = e(WWW,X,Y)\n",
    "    if e_new>e_:\n",
    "      alpha /=2\n",
    "    elif e_new<e_:\n",
    "      WWW = W_new\n",
    "      alpha *= 2\n",
    "    acc(WWW)\n",
    "  return WWW\n",
    "\n",
    "model = learnModel(X,Y,[4,10,3],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Input: [0, 0] Output: [0.5126588166210535]\n",
      "Input: [0, 1] Output: [0.4992429045125292]\n",
      "Input: [1, 0] Output: [0.5017889412431474]\n",
      "Input: [1, 1] Output: [0.4872145618152579]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Activation function (sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# Class for MLP\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights with random values\n",
    "        self.weights1 = [[random.uniform(-1, 1) for _ in range(input_size)] for _ in range(hidden_size)]\n",
    "        self.weights2 = [[random.uniform(-1, 1) for _ in range(hidden_size)] for _ in range(output_size)]\n",
    "        \n",
    "        # Initialize biases with random values\n",
    "        self.biases1 = [random.uniform(-1, 1) for _ in range(hidden_size)]\n",
    "        self.biases2 = [random.uniform(-1, 1) for _ in range(output_size)]\n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, inputs):\n",
    "        # Calculate hidden layer outputs\n",
    "        hidden_outputs = [0] * self.hidden_size\n",
    "        for i in range(self.hidden_size):\n",
    "            weighted_sum = 0\n",
    "            for j in range(self.input_size):\n",
    "                weighted_sum += inputs[j] * self.weights1[i][j]\n",
    "            hidden_outputs[i] = sigmoid(weighted_sum + self.biases1[i])\n",
    "        \n",
    "        # Calculate output layer outputs\n",
    "        output_outputs = [0] * self.output_size\n",
    "        for i in range(self.output_size):\n",
    "            weighted_sum = 0\n",
    "            for j in range(self.hidden_size):\n",
    "                weighted_sum += hidden_outputs[j] * self.weights2[i][j]\n",
    "            output_outputs[i] = sigmoid(weighted_sum + self.biases2[i])\n",
    "        \n",
    "        return output_outputs\n",
    "    \n",
    "    # Training the MLP using backpropagation\n",
    "    def train(self, inputs, targets, learning_rate):\n",
    "        # Forward propagation\n",
    "        hidden_outputs = [0] * self.hidden_size\n",
    "        for i in range(self.hidden_size):\n",
    "            weighted_sum = 0\n",
    "            for j in range(self.input_size):\n",
    "                weighted_sum += inputs[j] * self.weights1[i][j]\n",
    "            hidden_outputs[i] = sigmoid(weighted_sum + self.biases1[i])\n",
    "        \n",
    "        output_outputs = [0] * self.output_size\n",
    "        for i in range(self.output_size):\n",
    "            weighted_sum = 0\n",
    "            for j in range(self.hidden_size):\n",
    "                weighted_sum += hidden_outputs[j] * self.weights2[i][j]\n",
    "            output_outputs[i] = sigmoid(weighted_sum + self.biases2[i])\n",
    "        \n",
    "        # Backpropagation\n",
    "        output_errors = [0] * self.output_size\n",
    "        for i in range(self.output_size):\n",
    "            output_errors[i] = (targets[i] - output_outputs[i]) * output_outputs[i] * (1 - output_outputs[i])\n",
    "        \n",
    "        hidden_errors = [0] * self.hidden_size\n",
    "        for i in range(self.hidden_size):\n",
    "            error = 0\n",
    "            for j in range(self.output_size):\n",
    "                error += output_errors[j] * self.weights2[j][i]\n",
    "            hidden_errors[i] = error * hidden_outputs[i] * (1 - hidden_outputs[i])\n",
    "        \n",
    "        # Update weights and biases\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                self.weights2[i][j] += learning_rate * output_errors[i] * hidden_outputs[j]\n",
    "            self.biases2[i] += learning_rate * output_errors[i]\n",
    "        \n",
    "        for i in range(self.hidden_size):\n",
    "            for j in range(self.input_size):\n",
    "                self.weights1[i][j] += learning_rate * hidden_errors[i] * inputs[j]\n",
    "            self.biases1[i] += learning_rate * hidden_errors[i]\n",
    "\n",
    "# Example usage\n",
    "mlp = MLP(input_size=2, hidden_size=4, output_size=1)  # Create MLP with 2 input neurons, 4 hidden neurons, and 1 output neuron\n",
    "\n",
    "# Training data\n",
    "train_inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "train_targets = [[0], [1], [1], [0]]\n",
    "\n",
    "# Training the MLP\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in zip(train_inputs, train_targets):\n",
    "        mlp.train(inputs, targets, learning_rate)\n",
    "\n",
    "# Testing the MLP\n",
    "test_inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "\n",
    "print(\"Test Results:\")\n",
    "for inputs in test_inputs:\n",
    "    output = mlp.forward(inputs)\n",
    "    print(f\"Input: {inputs} Output: {output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
